{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation of the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import random as rd\n",
    "import ast \n",
    "import pandas as pd \n",
    "from igraph import Graph\n",
    "import community\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_data = pd.read_csv('instagram_accounts_corrected.csv', delimiter=';', encoding='ISO-8859-1')\n",
    "posts_data = pd.read_csv('instagram_posts_corrected.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the dictionnaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We decided to summarize all useful data in dictionnaries, as they are easier to work with, and allow the code to be faster.\n",
    "#This cell defines a dictionnary where the keys are identities of the users and the values a dictionnary summerizing all the characteristics of that user.\n",
    "accounts={}\n",
    "for index, row in accounts_data.iterrows():\n",
    "    user_id = str(row[\"id_user\"])\n",
    "    nbfollowers = row[\"nb_followers\"]\n",
    "    nbfollowing = row[\"nb_following\"]\n",
    "    nb_posts=row[\"nb_posts\"]\n",
    "    sex=row[\"sex\"]\n",
    "    followers = ast.literal_eval(row['id_followers'])\n",
    "    dept = row[\"department\"]\n",
    "    birth = row[\"birth_date\"]\n",
    "    accounts[user_id]={\"nb_followers\": nbfollowers, \"nbfollowing\": nbfollowing, \"nb_posts\": nb_posts, \"sex\":sex, \"id_followers\" : followers, \"department\":dept, \"birth_date\":birth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell defines a dictionnary where the keys are posts and the values a dictionnary summerizing all the characteristics of that post.\n",
    "posts={}\n",
    "\n",
    "for index, row in posts_data.iterrows():\n",
    "    post_id = str(row['id_post'])\n",
    "    user_id = str(row['id_user'])\n",
    "    time = row[\"time\"]\n",
    "    half_day = row[\"half_day\"]\n",
    "    views = row['views']\n",
    "    reposts = row[\"reposts\"]\n",
    "    likes=row[\"likes\"]\n",
    "    comments=row[\"comments\"]\n",
    "    id_post_origin = str(row['id_post_origin'])\n",
    "    link_clicks = row[\"link_clicks\"]\n",
    "    donation_tag = row[\"donation_tag\"]\n",
    "    donation_val = row[\"donation_val\"]\n",
    "    house_buy = row[\"house_buy\"]\n",
    "    posts[post_id]={\"id_user\":user_id, \"time\":time, \"half_day\": half_day, \"views\": views, \"reposts\": reposts, \"likes\": likes, \"comments\":comments, \"id_post_origin\" : id_post_origin, \"link_clicks\":link_clicks, \"donation_tag\":donation_tag, \"donation_val\":donation_val, \"house_buy\":house_buy}\n",
    "\n",
    "\n",
    "## Add a case has_posted to accounts which is True if user_id has posted the Orizon video, false otherwise\n",
    "for i in posts :\n",
    "    accounts[posts[i][\"id_user\"]][\"has_posted\"]=True\n",
    "    accounts[posts[i][\"id_user\"]][\"id_post\"]=i\n",
    "for i in accounts :\n",
    "    if \"has_posted\" not in accounts[i] :\n",
    "        accounts[i][\"has_posted\"]=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionnary where the keys are users' identities and the values a dictionnary combining all the useful data of posts and accounts\n",
    "#This dictionnary 'stats' will be useful for the calculation of the weights of the graph\n",
    "\n",
    "\n",
    "alpha = 0.0062773976757802595  # alpha corresponds to the probability that a user reposts a post it encounters if there is no data in instagram_posts_corrected\n",
    "beta = 0.0125134  # beta corresponds to the probability that a user makes a donation if there is no data in instagram_posts_corrected\n",
    "\n",
    "\n",
    "stats={}\n",
    "\n",
    "nb_donations=0\n",
    "nb_click=0\n",
    "for post, dic in posts.items():\n",
    "    w_views=dic[\"views\"]/(accounts[dic[\"id_user\"]][\"nb_followers\"])\n",
    "    w_likes=dic[\"likes\"]/(accounts[dic[\"id_user\"]][\"nb_followers\"])\n",
    "    w_comments=dic[\"comments\"]/(accounts[dic[\"id_user\"]][\"nb_followers\"])\n",
    "    w_donations = dic[\"donation_val\"]/accounts[dic[\"id_user\"]][\"nb_followers\"] if dic[\"donation_tag\"] else 0\n",
    "    w_has_donated=1/accounts[dic[\"id_user\"]][\"nb_followers\"] if dic[\"donation_tag\"] else 0\n",
    "    nb_donations+=1 if dic[\"donation_tag\"] else 0\n",
    "    if dic[\"link_clicks\"]:\n",
    "        w_click = 1/accounts[dic[\"id_user\"]][\"nb_followers\"] \n",
    "        nb_click += 1\n",
    "    else:\n",
    "        w_click = 0 \n",
    "    stats[dic[\"id_user\"]]={\"w_views\":w_views, \"w_likes\":w_likes, \"w_comments\":w_comments, \"w_donations\":w_donations, \"w_clicks\": w_click , \"w_has_donated\" : w_has_donated}\n",
    "\n",
    "for user in accounts :\n",
    "    w_repost={}\n",
    "    for follower in accounts[user][\"id_followers\"] :\n",
    "        if posts[accounts[str(follower)][\"id_post\"]][\"id_post_origin\"]==accounts[user][\"id_post\"] :\n",
    "            w_repost[str(follower)]=1\n",
    "        else :\n",
    "            w_repost[str(follower)]=alpha\n",
    "    stats[user][\"w_repost\"]=w_repost\n",
    "\n",
    "nb_click = nb_click/len(posts)\n",
    "nb_donations=nb_donations/len(posts)\n",
    "\n",
    "# stats[id_user][\"w_views\"] represents the contribution of each follower of id_user on the number of views accumulated by a Greenpeace post made by id_user\n",
    "#This contribution may be hypothetic : not every user has posted the Greenpeace video in our original data set. If this is the case, this contribution is the average of those which are not hypothetical \n",
    "# It is the same mechanism for stats[id_user][\"w_likes\"] and so on, except for\n",
    "# stats[id_user1][\"w_repost\"] is a dictionnary where stats[id_user1][\"w_repost\"][id_user2] is the number of repost made by id_user2 for every Greenpeace post of id_user1\n",
    "\n",
    "\n",
    "#Mean number of clicks, views, comments on every post.\n",
    "mean_likes=0\n",
    "mean_views=0\n",
    "mean_comments=0\n",
    "mean_clicks=0\n",
    "for i in posts:\n",
    "    mean_likes+=posts[i][\"likes\"]\n",
    "    mean_views+=posts[i][\"views\"]\n",
    "    mean_comments+=posts[i][\"comments\"]\n",
    "    if posts[i][\"link_clicks\"] :\n",
    "        mean_clicks+=1\n",
    "mean_likes=mean_likes/len(posts)\n",
    "mean_comments=mean_comments/len(posts)\n",
    "mean_views=mean_views/len(posts)\n",
    "mean_clicks=mean_clicks/len(posts)\n",
    "\n",
    "# Add keys to stats: number of views, comments, likes, donations, clicks. We distinguish two cases:\n",
    "# - If a user has posted the Orizon video, the dictionnary's values are the number of views, comments, likes, donations, clicks the post has.\n",
    "# - If a user has not posted the Orizon video the mean of those factors otherwise\n",
    "for i in stats :\n",
    "    if accounts[i][\"has_posted\"] :\n",
    "        stats[i][\"nb_views\"]=posts[accounts[i][\"id_post\"]][\"views\"]\n",
    "        stats[i][\"nb_likes\"]=posts[accounts[i][\"id_post\"]][\"likes\"]\n",
    "        stats[i][\"nb_comments\"]=posts[accounts[i][\"id_post\"]][\"comments\"]\n",
    "        if posts[accounts[i][\"id_post\"]][\"link_clicks\"] :\n",
    "            stats[i][\"nb_clicks\"]=1\n",
    "        else :\n",
    "            stats[i][\"nb_clicks\"]=0\n",
    "    else :\n",
    "        n_follow=len(accounts[i][\"id_followers\"])\n",
    "        stats[i][\"nb_views\"]=mean_views\n",
    "        stats[i][\"nb_likes\"]=mean_likes\n",
    "        stats[i][\"nb_comments\"]=mean_comments\n",
    "        stats[i][\"nb_clicks\"]=mean_clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ponderation of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_function(views,likes,comments,reposts,clicks,donations) :\n",
    "    \"\"\"the weight_function gives the weight of an edge.\"\"\"\n",
    "    \"\"\"If that edge is (a,b) then it is depending on the number of views made by b if a has posted the Orizon video and so on for the other variables\"\"\"\n",
    "    return (views+6.25*likes+28.01*comments+57.03*reposts+85.03*clicks+332*donations)/(1+6.25+28.01+57.03+85.03+332)\n",
    "\n",
    "\n",
    "weights={}\n",
    "# weights is of the form {(user_id1 , user_id2): weight} where (user_id1 , user_id2) is an edge of our oriented graph.\n",
    "for i in accounts :\n",
    "    for j in accounts[i][\"id_followers\"] :\n",
    "            weights[(str(i),str(j))]=weight_function(stats[str(i)][\"w_views\"], stats[str(i)][\"w_likes\"],stats[str(i)][\"w_comments\"],stats[str(i)][\"w_repost\"][str(j)],stats[str(i)][\"w_clicks\"],stats[str(i)][\"w_donations\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking of the edges of the graph with Page Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_rank_score(dico_weights) :\n",
    "    \"\"\"Determines the pagerank score of every vertex of the graph\"\"\"\n",
    "    edges=[]\n",
    "    for (i,j) in dico_weights :\n",
    "        edges.append((i,j,dico_weights[(i,j)]))\n",
    "    graph = Graph.TupleList(edges, directed=True, weights=True)\n",
    "    pagerank_scores = graph.pagerank(weights='weight')\n",
    "    pagerank_dict = dict(zip(graph.vs['name'], pagerank_scores))\n",
    "    return pagerank_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful appendix functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaries \"bijection\" and \"bijection_bis\" allow us to easily access a user's coordinates in the data thanks to its user identity, and vice versa\n",
    "bijection_bis= {i: user_id for i,\n",
    "                               user_id in enumerate(accounts_data['id_user'])}\n",
    "\n",
    "bijection={}\n",
    "for i in range(len(bijection_bis)) :\n",
    "    bijection[bijection_bis[i]]=i\n",
    "\n",
    "\n",
    "def matrice_adjacence(weights,d,accounts) :\n",
    "    \"\"\"This function transforms weigths and accounts into the corresponding adjacency_matrix\"\"\"\n",
    "    n=len(d)\n",
    "    M=[[0 for i in range(n)] for j in range(n)]\n",
    "    for i in accounts :\n",
    "        for j in accounts[i][\"id_followers\"] :\n",
    "            a=d[int(i)]\n",
    "            b=d[j]\n",
    "            M[a][b]=weights[(i,str(j))]\n",
    "    return np.array(M)\n",
    "\n",
    "\n",
    "def cout(id_utilisateur):\n",
    "    \"\"\"This function gives the cost of hiring a user in order to publish the Orizon video\"\"\"\n",
    "    return (accounts[str(id_utilisateur)][\"nb_followers\"] **2)/90\n",
    "\n",
    "\n",
    "def Tri(C):\n",
    "    \"\"\"This function sorts the list C\"\"\"\n",
    "    if len(C)<2:\n",
    "        return C\n",
    "    pivot_index = len(C) -1\n",
    "    pivot = C[-1]\n",
    "\n",
    "    elements_inf = [x for x in C[:pivot_index] if x[1] <= pivot[1]]\n",
    "    elements_sup = [x for x in C[:pivot_index] if x[1] > pivot[1]]\n",
    "\n",
    "    return Tri(elements_sup) + [pivot] + Tri(elements_inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitions of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Louvain(Graph):\n",
    "    \"\"\"This function uses the Louvain algorithm to determine the different clusters in our network graph\"\"\"\n",
    "    \n",
    "    # Créer un graphe à partir de la matrice d'adjacence\n",
    "    graph_louvain = nx.Graph(Graph)\n",
    "\n",
    "    # Exécuter l'algorithme de Louvain\n",
    "    partition = community.best_partition(graph_louvain)\n",
    "\n",
    "    return partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists of sponsors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dico_sponsor(C, partition, max_partition, nb_sponsors):\n",
    "    \"\"\"This function gives the user_id of the people the company should hire to post the Orizon video\"\"\"\n",
    "    sponsors = {}\n",
    "    k = 0\n",
    "    while k < max_partition:\n",
    "        k += 1\n",
    "        i = 0\n",
    "        while partition[C[i][0]] in sponsors.values():\n",
    "            i = i + 1\n",
    "        sponsors[C[i][0]] = partition[C[i][0]]\n",
    "        C.pop(i)\n",
    "    while k < nb_sponsors:\n",
    "        k += 1\n",
    "        sponsors[C[0][0]] = partition[C[0][0]]\n",
    "        C.pop(0)\n",
    "    while k > nb_sponsors:\n",
    "        k -= 1\n",
    "        sponsors.popitem()\n",
    "    return sponsors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def degre():\n",
    "    L = []\n",
    "    for user_id in accounts:\n",
    "        L.append((bijection[int(user_id)],accounts[user_id][\"nb_followers\"]))\n",
    "    return Tri(L)\n",
    "L = degre()\n",
    "LL=[]\n",
    "for (a,b) in L :\n",
    "    LL.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of the propagation once we have the list of our sponsors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(set_users, adjacency_matrix):\n",
    "    '''\n",
    "    This function forecasts the results of the campaign. It needs to have the graph of the network and the \n",
    "    user_ids of the people hired by Greenpeace in order to post the Orizon video\n",
    "    '''\n",
    "    n1 = len(set_users) # Determine the number of users in the campaign. The variable set_users contains the users our method consider are best to sponsor\n",
    "    \n",
    "    results = {\"views\": 0, \"likes\": 0, \"comments\": 0,\n",
    "               \"reposts\": 0, \"clicks\": 0, \"donations\": 0} #Here, we define a dictionnary which contains all the metrics were interested in in this study. The values are going to be the results of the campaign\n",
    "    \n",
    "    n = len(adjacency_matrix)\n",
    "    for k in range(10): # We iterate over the campaign simulation for 10 rounds\n",
    "        posters = [] # This list contains all the users who are going to repost at a certain moment \n",
    "        set_users_bis=set_users.copy()\n",
    "        while len(set_users_bis) != 0: #We run the code until there are no influencers left. For each iteration, we simulate the propagation over the graph\n",
    "            user = set_users_bis.pop()\n",
    "            posters.append(user)\n",
    "            \n",
    "            for j in range(n): #We find the followers of each poster/reposter, to increase the stats of the campaign\n",
    "                if adjacency_matrix[user][j] != 0 and j not in posters and j not in set_users_bis: #We analyse if there is a probability that one of the followers reposts\n",
    "                    if stats[str(bijection_bis[user])][\"w_repost\"][str(bijection_bis[j])]==1 :\n",
    "                        set_users_bis.append(j) #We add this follower to posters, so his followers can now have access to the post\n",
    "                    else :\n",
    "                        p=100000*stats[str(bijection_bis[user])][\"w_repost\"][str(bijection_bis[j])]\n",
    "                        c=rd.randint(1,100000)\n",
    "                        if c<=p :\n",
    "                            set_users_bis.append(j) #We add this follower to posters, so his followers can now have access to the post\n",
    "                            \n",
    "        for poster in posters : #Then, we had the conresponding stats for each repost, increasing the reach of the campaign\n",
    "            results[\"views\"] += stats[str(bijection_bis[poster])][\"nb_views\"]\n",
    "            results[\"likes\"] += stats[str(bijection_bis[poster])][\"nb_likes\"]\n",
    "            results[\"comments\"] += stats[str(bijection_bis[poster])][\"nb_comments\"]\n",
    "            results[\"clicks\"] += stats[str(bijection_bis[poster])][\"nb_clicks\"]\n",
    "            results[\"donations\"] += stats[str(bijection_bis[poster])][\"w_donations\"]*accounts[str(bijection_bis[poster])][\"nb_followers\"]\n",
    "        results[\"reposts\"] += len(posters)-n1\n",
    "        \n",
    "    for key in results: #We have to divide by 10 to take in account the fact that we did 10 simulations of propagation on the graph\n",
    "        results[key] = results[key]/10\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns hired_users, the people the company should hire to post the Orizon video in order to maximize the impact of the campaign and then the results of the campaign\n",
    "d=page_rank_score(weights)\n",
    "page_rank_list=[]\n",
    "for vertex in d :\n",
    "    page_rank_list.append((bijection[int(vertex)],d[vertex]/(cout(vertex))))\n",
    "page_rank_list_sorted=Tri(page_rank_list)\n",
    "partition=Louvain(matrice_adjacence(weights,bijection,accounts))\n",
    "hired_users=dico_sponsor(page_rank_list_sorted,partition,max(partition.values())+1,1)\n",
    "usersList = list(hired_users.keys())\n",
    "matrix = matrice_adjacence(weights, bijection, accounts)\n",
    "\n",
    "cout_sponsors_initiaux = [cout(bijection_bis[i]) for i in range(4)]\n",
    "cout_sponsors = [cout(bijection_bis[x]) for x in usersList]\n",
    "\n",
    "#Simulation\n",
    "results = forecast(usersList,matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes for presenting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results with the degree method\n",
    "res=forecast(LL[:4],matrix)\n",
    "print(res)\n",
    "print(LL[:4])\n",
    "\n",
    "somme = [cout(bijection_bis[x]) for x in LL[:4]]\n",
    "\n",
    "print(sum(somme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results with random sponsors\n",
    "hired_users=[]\n",
    "for i in range(4) :\n",
    "    p=rd.randint(0,3046)\n",
    "    if p not in hired_users :\n",
    "        hired_users.append(p)\n",
    "forecast(hired_users,matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "somme_originale = [cout(bijection_bis[x]) for x in [0,1,2,3]]\n",
    "print(sum(somme_originale))\n",
    "\n",
    "somme_originale = [cout(bijection_bis[x]) for x in hired_users]\n",
    "print(sum(somme_originale))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
